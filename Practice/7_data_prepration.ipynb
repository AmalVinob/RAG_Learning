{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97673078-c5c4-46ae-8477-7935ba4dc0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index==0.10.37 in c:\\users\\1090135\\appdata\\local\\anaconda3\\envs\\lil_llama_index\\lib\\site-packages (0.10.37)\n",
      "Requirement already satisfied: llama-index-readers-smart-pdf-loader in c:\\users\\1090135\\appdata\\local\\anaconda3\\envs\\lil_llama_index\\lib\\site-packages (0.3.0)\n",
      "Collecting pymupdf\n",
      "  Using cached pymupdf-1.25.3-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement llamasherpa (from versions: none)\n",
      "ERROR: No matching distribution found for llamasherpa\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index==0.10.37 llama-index-readers-smart-pdf-loader pymupdf llamasherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c83f93-18f2-4402-9381-bfb202213326",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet llmsherpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8522627-096d-45f8-8363-6d8b49542539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "702bd1a2-41a2-4033-b026-a5b712f79bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CO_API_KEY = os.environ['CO_API_KEY'] or getpass(\"Enter your Cohere API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0162fb2-2c7b-4f98-ab98-7396c332cd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(\n",
    "    text: str,\n",
    "    extra_whitespace: bool = False,\n",
    "    broken_paragraphs: bool = False,\n",
    "    bullets: bool = False,\n",
    "    ascii: bool = False,\n",
    "    lowercase: bool = False,\n",
    "    citations: bool = False,\n",
    "    merge_split_words: bool = False,\n",
    "\n",
    ") -> str:\n",
    "    \"\"\"Cleans text.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_text = text.lower() if lowercase else text\n",
    "    cleaned_text = (\n",
    "        clean_non_ascii_chars(cleaned_text) if ascii else cleaned_text\n",
    "    )\n",
    "    cleaned_text = remove_citations(cleaned_text) if citations else cleaned_text\n",
    "    cleaned_text = clean_extra_whitespace(cleaned_text) if extra_whitespace else cleaned_text\n",
    "    cleaned_text = clean_bullets(cleaned_text) if bullets else cleaned_text\n",
    "    cleaned_text = merge_hyphenated_words(cleaned_text) if merge_split_words else cleaned_text\n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ea6c6b2-1169-496b-a627-ae879626663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"../data/almanack_of_naval_ravikant.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8a5d3-e589-402b-9686-c01d8844fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_PATH = \"./data/pg10763.txt\"\n",
    "\n",
    "url = \"copyright\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78eb14ee-cde3-4255-91b7-ca5f8d4bd996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "# from llama_index.readers.file import PDFReader\n",
    "# from llama_index.readers.smart_pdf_loader import SmartPDFLoader\n",
    "\n",
    "text_loaded = SimpleDirectoryReader(input_files=[TEXT_PATH]).load_data()\n",
    "\n",
    "pdf_loaded = SimpleDirectoryReader(input_files=[PDF_PATH]).load_data()\n",
    "# smart_pdf_loader_docs = SmartPDFLoader(llmsherpa_api_url=LLMSHERPA_API_URL).load_data(PDF_PATH)\n",
    "\n",
    "# pdf_reader_docs = PDFReader().load_data(PDF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ba3bc00-f032-44e3-8c35-9cc077365cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING  JUDGMENT ·  101SHED YOUR IDENTITY TO SEE REALITY\n",
      "Our egos are constructed in our formative years—our first \n",
      "two decades. They get constructed by our environment, our \n",
      "parents, society. Then, we spend the rest of our life trying to \n",
      "make our ego happy. We interpret anything new through our \n",
      "ego: “How do I change the external world to make it more how \n",
      "I would like it to be?” [8]\n",
      "“Tension is who you think you should be.  \n",
      "Relaxation is who you are.”\n",
      "—Buddhist saying\n",
      "You absolutely need habits to function. You cannot solve every \n",
      "problem in life as if it is the first time it’s thrown at you. We \n",
      "accumulate all these habits. We put them in the bundle of \n",
      "identity, ego, ourselves, and then we get attached to them. “I’m \n",
      "Naval. This is the way I am.”\n",
      "It’ s really important to be able to uncondition yourself, to be \n",
      "able to take your habits apart and say, “Okay, this is a habit I \n",
      "probably picked up when I was a toddler trying to get my par-\n",
      "ent’s attention. Now I’ve reinforced it and reinforced it, and \n",
      "I call it a part of my identity. Does it still serve me? Does it \n",
      "make me happier? Does it make me healthier? Does it make \n",
      "me accomplish whatever I set out to accomplish?”\n",
      "I’m less habitual than most people. I don’t like to structure \n",
      "my day. To the extent I have habits, I try to make them more \n",
      "deliberate rather than accidents of history. [4]\n"
     ]
    }
   ],
   "source": [
    "print(pdf_loaded[100].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64e1781e-fb62-4e66-ad66-1a924f049f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_chapter_headers_footers(strings, flag):\n",
    "    \"\"\"\n",
    "    Modify a list of strings based on a specified flag and join them into a single string.\n",
    "\n",
    "    This function first removes any empty strings from the input list. It then checks if the\n",
    "    remaining list has more than three elements. If so, it modifies the list by removing the\n",
    "    first element, last element, or both, based on the value of the flag. The final list is then\n",
    "    joined into a single string with spaces separating the elements.\n",
    "\n",
    "    Parameters:\n",
    "        strings (list of str): The list of strings to modify.\n",
    "        flag (str): A flag indicating the modification to perform on the list:\n",
    "            - 'remove_first': Remove the first element of the list.\n",
    "            - 'remove_last': Remove the last element of the list.\n",
    "            - 'remove_first_last': Remove both the first and last elements of the list.\n",
    "            - 'remove_first_two': Remove the first two elements of the list.\n",
    "            - Any other value leaves the list unchanged.\n",
    "\n",
    "    Returns:\n",
    "        str: A single string composed of the modified list elements, separated by spaces.\n",
    "    \"\"\"\n",
    "    # Filter out empty strings\n",
    "    filtered_strings = [s for s in strings if s]\n",
    "    \n",
    "    # Check if the filtered list has more than three elements\n",
    "    if len(filtered_strings) > 3:\n",
    "        if flag == 'remove_first':\n",
    "            filtered_strings = filtered_strings[1:]  # Slice off the first element\n",
    "        elif flag == 'remove_last':\n",
    "            filtered_strings = filtered_strings[:-1]  # Slice off the last element\n",
    "        elif flag == 'remove_first_last':\n",
    "            filtered_strings = filtered_strings[1:-1]  # Slice off the first and last elements\n",
    "        elif flag == 'remove_first_two':\n",
    "            filtered_strings = filtered_strings[2:]  # Slice off the first two elements\n",
    "    \n",
    "    # Join all strings with a space and return the result\n",
    "    return ' '.join(filtered_strings).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44fbb3cc-a336-435d-aa02-697297b60eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(page, file_name, title, author, flag, opt=\"text\"):\n",
    "    \"\"\"\n",
    "    Extracts text from a specified page of a document and returns a dictionary containing\n",
    "    the extracted text and associated metadata.\n",
    "\n",
    "    The function first retrieves text from the given `page` object using the specified `opt` method.\n",
    "    It then processes this text to remove chapter headers, footers, and applies various cleaning\n",
    "    procedures according to the `flag` and other parameters set in the `clean` function.\n",
    "\n",
    "    Parameters:\n",
    "        page (fitz.Page): The page object from which to extract text.\n",
    "        file_name (str): The name of the file from which the page is taken.\n",
    "        title (str): The title of the document.\n",
    "        author (str): The author of the document.\n",
    "        flag (str): A flag used to customize how chapter headers and footers are handled.\n",
    "        opt (str, optional): The method of text extraction to be used by `get_text`.\n",
    "            Defaults to \"text\", but can be changed to other methods supported by the library.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with two keys:\n",
    "            - 'text': A string containing the cleaned and processed text from the page.\n",
    "            - 'metadata': A dictionary containing metadata about the text, including the\n",
    "                          page number, file name, title, and author.\n",
    "    \"\"\"\n",
    "    \n",
    "    text = page.get_text(opt, sort=True)\n",
    "\n",
    "    text = text.split(\"\\n\")\n",
    "\n",
    "    text = handle_chapter_headers_footers(text, flag)\n",
    "\n",
    "    text = clean(\n",
    "        text,\n",
    "        extra_whitespace=True,\n",
    "        broken_paragraphs=True,\n",
    "        bullets=True,\n",
    "        ascii=True,\n",
    "        lowercase=False,\n",
    "        citations=True,\n",
    "        merge_split_words=True,\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"metadata\": {\n",
    "            \"page_number\": page.number,\n",
    "            \"file_name\": file_name,\n",
    "            \"title\": title,\n",
    "            \"author\": author\n",
    "        }\n",
    "    }\n",
    "\n",
    "def extract_texts_from_pdf(file_path, title, author, pages, flag):\n",
    "    document = get_document(file_path, pages)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    extracted_texts = [extract_text(page, file_path, title, author, flag) for page in document]\n",
    "    return extracted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e9d5a7-4553-44f0-92cf-a7aed8f6cbde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex (LinkedIn Learning)",
   "language": "python",
   "name": "lil_llama_index"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
